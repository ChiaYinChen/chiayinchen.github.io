---
title: 'Titanic: Machine Learning from Disaster'
author: Chia-Yin Chen
date: '2017-12-28'
categories:
  - R
tags:
  - kaggle
  - classification
output:
  blogdown::html_page:
    toc: true
    number_sections: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
這份報告選擇了 Kaggle 的 Titanic 資料集，運用機器學習 (machine learning) 技術來預測鐵達尼號沉船後哪些乘客會存活下來。

## 匯入資料 (Import Data)
首先讀取 titanic 的**訓練 train.csv **與**測試 test.csv **資料，其中 test.csv 是一個沒有 Survived 答案的 csv 檔案。

```{r}
# 資料讀取
titanic_train <- read.csv("https://storage.googleapis.com/kaggle_titanic/train.csv")
titanic_test <- read.csv("https://storage.googleapis.com/kaggle_titanic/test.csv")

# 新增 `Set` 變數來分辨訓練與測試資料
titanic_train$Set <- "Train"
titanic_test$Set <- "Test"

# 合併訓練與測試資料
titanic_test$Survived <- NA
full_data <- rbind(titanic_train, titanic_test)
```

## 觀察資料外觀 (Data Overview)
```{r}
str(full_data) # The structure of titanic dataset
```

得知 titanic 資料集有 1309 個觀測值與 13 個變數，[資料欄位說明](https://www.kaggle.com/c/titanic/data)如下表：

```{r echo=FALSE}
Variable <- c("PassengerId", "Survived", "Pclass", "Name", "Sex", "Age", "SibSp", "Parch", "Ticket", "Fare", "Cabin", "Embarked", "Set")
Definition <- c("分配給每個乘客的唯一編號", "生存與否的指標", "船票的艙等，代表社會經濟地位", "乘客姓名", "乘客性別", "乘客年齡 (單位：年)", "乘客的兄弟姐妹或配偶在船上的人數", "乘客的父母或孩子在船上的人數", "船票編號", "船票價格", "乘客佔用的客艙號碼", "乘客登船的港口", "識別訓練與測試資料")
Key <- c("", "0 = 死亡, 1 = 存活", "1 = Upper, 2 = Middle, 3 = Lower", "", "", "", "", "", "", "", "", "C = Cherbourg, Q = Queenstown, S = Southampton", "")

titanic_table <- data.frame(Variable, Definition, Key)
library(knitr)
kable(titanic_table)
```

<p></p>

```{r}
summary(full_data) # The summary of titanic dataset
```

觀察到 **Age** 變數有 263 個遺漏值，**Fare** 變數有 1 個遺漏值，**Cabin** 變數有 1014 個空值，**Embarked** 變數有 2 個空值，由於 Cabin 變數的空值太多了，因此在訓練模型時將不考慮加入此變數，其他 Age、Fare、Embarked 變數會在「遺漏值處理 (Impute Missing Value)」的小節進行遺漏值填補。

# 特徵工程 (Feature Engineering)
有句話讓我印象很深刻：**「數據和特徵決定了機器學習的上限，而模型和算法只是逼近這個上限而已」**。為了讓我的預測模型 performance 更出色，我需要為我的預測模型獲取到更好的訓練特徵資料。

## Passenger Title
**Name** 變數的格式為：" Surname (姓), Title (頭銜). Firstname (名)... "，可以從乘客姓名中將[頭銜 (Title)](https://en.wikipedia.org/wiki/English_honorifics) 提取出來成為有意義的資訊。
```{r fig.align='center'}
# 自訂一個可以提取乘客 Title 的函數
get_Title <- function(data) {
  title_start <- regexpr(pattern = "\\,[A-Za-z ]{1,20}\\.", data$Name)
  title_end <- title_start + attr(title_start, "match.length") - 1
  data$Title <- substr(data$Name, start = title_start + 2, stop = title_end - 1)
  return(data$Title)
}

full_data$Title <- get_Title(full_data)
# 列出 Title 類別數量
table(full_data$Title)

# 整理歸類及重新定義一些 Title
full_data$Title[full_data$Title %in% c("Capt", "Col", "Don", "Dona", "Dr", "Major", "Rev")] <- "Officer" # 高層職位
full_data$Title[full_data$Title %in% c("Lady", "the Countess", "Sir", "Jonkheer")] <- "Noble" # 貴族、皇族
full_data$Title[full_data$Title == "Mme"] <- "Mrs"  # 夫人、太太
full_data$Title[full_data$Title %in% c("Ms", "Mlle")] <- "Miss"  # 女士、小姐
full_data$Title <- factor(full_data$Title)

# 列出整理過後的 Title 類別數量
table(full_data$Title)

# 視覺化 `Title` 與 `Survived` 之間的關係
library(ggplot2)
ggplot(full_data[full_data$Set == "Train", ], aes(x = Title, fill = factor(Survived))) +
  geom_bar(stat = "count", position = "dodge") +
  xlab("Title") +
  ylab("Count") +
  ggtitle("Passenger Survival Counts by Title") +
  theme(legend.position = "right",
        plot.title = element_text(size = 15, hjust = 0.5)) +
  scale_fill_discrete(guide = guide_legend(title = "survived"),
                      labels = c("NO", "YES")) +
  geom_text(stat = "count", aes(label = ..count..),
            position = position_dodge(width = 0.9), vjust = -0.25, size = 3)
```

可觀察到 Title 為 **Miss** 和 **Mrs** 存活的機會比較大，Title 為 **Mr** 的存活機會明顯小很多，也間接告訴我們男性倖存者明顯少於女性。

## Children vs. Women vs. Men
```{r message=FALSE, warning=FALSE, fig.align='center'}
# 視覺化 `Age` 在不同的 `Sex` 中與 `Survived` 之間的關係
ggplot(full_data[full_data$Set == "Train", ], aes(x = Age, fill = factor(Survived))) +
  geom_histogram() +
  facet_wrap(~ Sex) +
  xlab("Age") +
  ylab("Count") +
  ggtitle("Passenger Survival Counts by Age and Sex") +
  theme(legend.position = "right",
        plot.title = element_text(size = 15, hjust = 0.5)) +
  scale_fill_discrete(guide = guide_legend(title = "survived"),
                      labels = c("NO", "YES"))
```

視覺化明顯告訴我們不論在哪個年齡階段女性的存活機會都比較高，並可觀察到不論是在男性還是女性，15 歲以下的孩童存活機會都比較高。因此決定以 15 歲來區分孩童及成人對 **Survived** 的影響。

```{r}
# 建立新的變數 `Child` ，辨識 "孩童"、"成人"
full_data$Child[full_data$Age < 15] <- "Child"
full_data$Child[full_data$Age >= 15] <- "Adult"
full_data$Child <- factor(full_data$Child)
```

鐵達尼號逃生時究竟是老弱婦孺優先上救生艇？還是有錢人先上救生艇？

```{r fig.align='center'}
# 建立新的變數 `identity`，辨識 "男性孩童"、"女性孩童"、"男性成人"、"女性成人"
full_data$identity[full_data$Age >= 15 & full_data$Sex == "male"] <- "Man"
full_data$identity[full_data$Age >= 15 & full_data$Sex == "female"] <- "Woman"
full_data$identity[full_data$Age < 15 & full_data$Sex == "male"] <- "Boy"
full_data$identity[full_data$Age < 15 & full_data$Sex == "female"] <- "Girl"
full_data$identity <- factor(full_data$identity)

# 視覺化 `identity` 在不同的 `Pclass` 中與 `Survived` 之間的關係
full_data$Pclass <- factor(full_data$Pclass)
ggplot(full_data[full_data$Set == "Train" & !is.na(full_data$Age), ],
       aes(x = identity, fill = factor(Survived))) +
  geom_bar(stat = "count", position = "dodge") +
  facet_wrap(~ Pclass, labeller = label_both) +
  xlab("Identity") +
  ylab("Count") +
  ggtitle("Passenger Survival Counts by Identity and Pclass") +
  theme(legend.position = "right",
        plot.title = element_text(size = 15, hjust = 0.5)) +
  scale_fill_discrete(guide = guide_legend(title = "survived"),
                      labels = c("NO", "YES")) +
  geom_text(stat = "count", aes(label = ..count..),
            position = position_dodge(width = 0.9), vjust = -0.25, size = 3)
```

註：【1】Boy：age < 15 & Sex == "male"【2】Girl：age < 15 & Sex == "female"【3】Man：Age >= 15 & Sex == "male"【4】Woman：Age >= 15 & Sex == "female"

視覺化顯示確實和電影演的一樣，逃生時婦女兒童優先上救生艇，大量的孩童和女性都存活了下來。但也發現到一個殘酷的事實，雖然船長發出了婦女和兒童優先上救生艇的口號，但逃生的機會還是取決於乘客當時所在的艙等，可發現Pclass = 3 (Lower艙等) 的乘客不管是孩童還是成人存活的機會都不高，Pclass = 1 (Upper艙等) 和Pclass = 2 (Middle艙等) 存活的機會高了些，所以其實只是 Upper 艙等和 Middle 艙等的婦女和兒童優先而已，間接說明了有錢人還是比窮人先活下來了...

## Solo Travel vs. Group Travel
**SibSp** (兄弟姐妹或配偶在船上的人數) 及 **Parch** (直系的親人在船上的人數) 這兩個變數包含了有關乘客家庭的隱藏資訊，利用這兩個變數製作一個新的變數叫作 **family_size** (家庭人口大小)。
```{r fig.align='center', fig.width=10, fig.height=6}
# 建立新的變數 `family_size`，包括乘客本人
full_data$family_size <- full_data$SibSp + full_data$Parch + 1

# 視覺化 `family_size` 與 `Survived` 之間的關係
library(gridExtra)
gg1 <- ggplot(full_data[full_data$Set == "Train", ], aes(x = family_size, fill = factor(Survived))) +
  geom_bar(stat = "count", position = "dodge") +
  scale_x_continuous(breaks = c(1:11)) +
  xlab("Family Size") +
  ylab("Count") +
  ggtitle("Passenger Survival Counts by Family Size") +
  theme(legend.position = "bottom",
        plot.title = element_text(size = 15, hjust = 0.5)) +
  scale_fill_discrete(guide = guide_legend(title = "survived"),
                      labels = c("NO", "YES")) +
  geom_text(stat = "count", aes(label = ..count..),
            position = position_dodge(width = 0.9), vjust = -0.25, size = 3)
gg2 <- ggplot(full_data[full_data$Set == "Train", ], aes(x = family_size, fill = factor(Survived))) +
  geom_bar(stat = "count", position = "fill") +
  scale_x_continuous(breaks = c(1:11)) +
  scale_y_continuous(labels = scales::percent) +
  xlab("Family Size") +
  ylab("Percentage") +
  ggtitle("Passenger Survival Rates by Family Size") +
  theme(legend.position = "bottom",
        plot.title = element_text(size = 15, hjust = 0.5)) +
  scale_fill_discrete(guide = guide_legend(title = "survived"),
                      labels = c("NO", "YES"))
grid.arrange(gg1, gg2, ncol=2)
```

上圖的視覺化告訴我們乘客的旅行人數是會影響生存情況的，不管是從「依照家庭人口數來計算倖存者的數量 (左圖)」還是從「依照家庭人口數來劃分倖存者的比例 (右圖)」的角度來看存活性，都可以發現 **1 < 家庭人口 < 5** 存活的可能性比 **家庭人口 = 1** 和 **家庭人口 > 4** 來的高。

另外，還可以再發現家庭人口為 1 的人數佔的好高！他們不是和家人一起旅遊，有可能是和朋友、情人、親友、傭人等人一起旅行，或者是獨自旅行。

所以呢只知道是否為家庭旅遊還不夠，我們再做更進階的探勘：一起購票的家庭或是團體似乎有相同的船票編號，利用 **Ticket** 變數 (船票編號) 來辨識乘客是獨自旅行還是團體旅行。最後再用視覺化來觀察一下！

```{r message=FALSE, warning=FALSE, fig.align='center'}
# 將 `family_size` 變數分成 "非家庭旅行"、"小家庭旅行" 和 "大家庭旅行" 三個層面，存放在新建立的變數 `family_type`
full_data$family_type[full_data$family_size == 1] <- "非家庭旅行"
full_data$family_type[full_data$family_size > 1 & full_data$family_size < 5] <- "小家庭旅行"
full_data$family_type[full_data$family_size > 4] <- "大家庭旅行"
full_data$family_type <- factor(full_data$family_type)

# 使用 `Ticket` 變數製作 `group_size` 變數 (團體旅遊人數)
library(magrittr)
library(dplyr)
full_data <- full_data %>%
  mutate(travel_group = match(Ticket, unique(Ticket)))

full_data$travel_group <- factor(full_data$travel_group)

full_data <- full_data %>%
  group_by(travel_group) %>%
  mutate(group_size = n())

# 將 `非家庭旅行` 及 `團體旅遊人數為 1 人` 的乘客認定為 "獨自旅行"
full_data$family_type <- as.character(full_data$family_type)
full_data[full_data$family_type == "非家庭旅行" & full_data$group_size == 1, ]$family_type <- "獨自旅行"
full_data$family_type <- factor(full_data$family_type)

# 視覺化 `family_type` 與 `Survived` 之間的關係
library(vcd)
mosaicplot(full_data[full_data$Set == "Train", ]$family_type ~ full_data[full_data$Set == "Train", ]$Survived,
           main="Passenger Survival by Family Type",
           shade = FALSE, color = TRUE,
           xlab = "Family Type", ylab = "Survived",
           cex.axis = 1)
```

註：視覺化中的**非家庭旅行**包括朋友、情人、親友、傭人等人一起旅行。

可觀察到大多數的乘客都是 "獨自旅行" 的，但存活的比例似乎不太高，反而是 "小家庭旅行" 存活的機會大於 50%，

# 遺漏值處理 (Impute Missing Value)

**---------------------------------------------------------遺漏值：Embarked----------------------------------------------------------**
```{r fig.width=10}
# 看一下 `Embarked` 2 個空值的觀測值
data.frame(full_data[full_data$Embarked == "", ])
```

可以觀察到編號 62 和 830 的乘客資訊很相似，差別只在於年紀的不同而已，同樣支付了 $80 票價，且都是 Upper 艙等，但都不知道是從哪個港口上船的。我們假設相同票價的乘客是在同一個港口上船的，可以用 **票價 Fare** 和 **艙等 Pclass** 來推估乘客會從哪一個 **港口出發 Embarked**。

```{r warning=FALSE, fig.align='center'}
# 視覺化 `Fare`、`Embarked` 與 `Pclass` 之間的關係
ggplot(full_data[full_data$Embarked != "", ], aes(x = Embarked, y = Fare, fill = Pclass)) +
  geom_boxplot() +
  geom_hline(aes(yintercept = 80),
             colour = "#9933ff", lty = 2, size = 2) +
  scale_y_continuous(labels = scales::dollar) + 
  geom_text(aes(3.4, 80, label = "$80", vjust = -1), size = 6, colour = "#9933ff") +
  scale_fill_discrete(guide = guide_legend(title = "Pclass"),
                      labels = c("Upper", "Middle", "Lower")) +
  scale_x_discrete(labels = c("Cherbourg", "Queenstown", "Southampton"))
```

編號 62 和 830 乘客支付的費用 $80 洽好和從 Cherbourg 港口出發的 Upper 艙等乘客中位票價一樣，因此他們很有可能是從 Cherbourg 港口上船的，我們可以用 "C" 替換空值。

```{r}
# 填補 `Embarked` 遺漏值
full_data$Embarked <- as.character(full_data$Embarked)
full_data[full_data$Embarked == "", ]$Embarked <- "C"
full_data$Embarked <- factor(full_data$Embarked)
```

**-------------------------------------------------------------遺漏值：Fare--------------------------------------------------------------**

```{r}
# 看一下遺漏 `Fare` 的觀測值
data.frame(full_data[is.na(full_data$Fare), ])
```

可以知道編號 1044 的乘客是從 Southampton 港口出發的 Lower 艙等，但不知道票價是多少。我們可以用剛剛填補登船港口遺漏值的思維，用**港口出發 Embarked** 地點和**艙等 Pclass** 來推估乘客會落在哪一個**票價 Fare**。

```{r warning=FALSE, message=FALSE, fig.align='center'}
# 視覺化從 Southampton 港口出發的 Lower 艙等乘客的票價
ggplot(full_data[full_data$Pclass == "3" & full_data$Embarked == "S", ], aes(x = Fare)) +
  geom_density(fill = "#0080ff", alpha=0.3) +
  geom_vline(aes(xintercept = median(Fare, na.rm = TRUE)),  # Pclass=3 & Embarked="S"的median Fare
             colour = "red", lty = 2, size = 1) +
  scale_x_continuous(labels = scales::dollar) +
  xlab("Fare") +
  ylab("Density") +
  ggtitle("從 Southampton 港口出發的 Lower 艙等乘客的票價") +
  theme(plot.title = element_text(size = 15, hjust = 0.5),
        panel.grid.minor = element_blank())
```

從 Southampton 港口出發的 Lower 艙等乘客的票價大部分分布在 $0~$20 之間，資料呈現右偏分配，存在比較大的離群值，由於中位數較平均數不容易受離群值的影響，因此標一條紅色虛線表示中位數來觀察一下，意外的發現票價的中位數恰好為眾數！我們可以將編號 1044 乘客的遺漏值 **Fare** 用中位數來替換，對於這個乘客付出這樣的價錢似乎也蠻合理的。

```{r}
# 依照乘客所屬 `Pclass` 與 `Embarked` 的中位數替換票價遺漏值
full_data[is.na(full_data$Fare), ]$Fare <- median(full_data[full_data$Pclass == "3" & full_data$Embarked == "S", ]$Fare, na.rm = TRUE)
```

**-------------------------------------------------------------遺漏值：Age--------------------------------------------------------------**

```{r warning=FALSE, fig.width=9, fig.height=5, fig.align='center'}
# 視覺化 `Title` 在不同的 `Pclass` 中與 `Age` 之間的關係
ggplot(full_data, aes(x = Title, y = Age, fill = Title)) +
  geom_boxplot() +
  facet_wrap(~ Pclass, labeller = label_both) +
  stat_summary(fun.y = mean, colour = "white", geom = "point", size = 2, show_guide = FALSE)
```

發現艙等等級會隨著年齡而變化，年齡越大的乘客購買艙等的等級就越高。在 Pclass = 1 (Upper艙等) 乘客的年齡普遍都比較大，且 Title 為 Master 乘客的年齡都頗小的。

資料中存在離群值，因此標一個白色圓點表示平均值，來觀察平均值是否受離群值影響很大。視覺化顯示平均值和中位數兩者間的差異沒有到很大，因此決定把遺漏值 **Age** 依照 **Title** 與 **Pclass** 的平均年齡進行填補。

```{r fig.align='center'}
# 結合 `Title` 與 `Pclass` 計算平均年齡
mean_age_by_Title_and_Pclass <- full_data %>%
  group_by(Title, Pclass) %>%
  summarise(mean_age = round(mean(Age, na.rm = TRUE), 2))
mean_age_by_Title_and_Pclass

# 視覺化 Age 為遺漏值的乘客 `Title` 與 `Pclass` 之間的關係
ggplot(full_data[is.na(full_data$Age), ], aes(x = Title, fill = Pclass)) +
  geom_bar(stat = "count", position = "dodge") +
  xlab("Title") +
  ylab("Count") +
  ggtitle("Missing Age Passenger Pclass Counts by Title") +
  theme(legend.position = "right",
        plot.title = element_text(size = 15, hjust = 0.5)) +
  scale_fill_discrete(guide = guide_legend(title = "Pclass"),
                      labels = c("1st = Upper", "2nd = Middle", "3rd = Lower")) +
  geom_text(stat = "count", aes(label = ..count..),
            position = position_dodge(width = 0.9), vjust = -0.25, size = 3)
```

可注意到在 Age 為遺漏值的乘客中，並不是每個 Title 類別在三個艙等都有遺漏值，例如 Title 為 Master 的乘客中 Age 為遺漏值的只有在 Lower 艙等而已，Title 為 Noble 的乘客中 Age 皆無遺漏值，以此類推...。因此在填補 Age 遺漏值時要與 mean_age_by_Title_and_Pclass 的順序對應好。

```{r}
# 依照 `Title` 與 `Pclass` 的平均年齡替換年齡遺漏值
full_data[is.na(full_data$Age) & full_data$Title == "Master" & full_data$Pclass == "3", ]$Age <- mean_age_by_Title_and_Pclass$mean_age[3]
full_data[is.na(full_data$Age) & full_data$Title == "Miss" & full_data$Pclass == "1", ]$Age <- mean_age_by_Title_and_Pclass$mean_age[4]
full_data[is.na(full_data$Age) & full_data$Title == "Miss" & full_data$Pclass == "2", ]$Age <- mean_age_by_Title_and_Pclass$mean_age[5]
full_data[is.na(full_data$Age) & full_data$Title == "Miss" & full_data$Pclass == "3", ]$Age <- mean_age_by_Title_and_Pclass$mean_age[6]
full_data[is.na(full_data$Age) & full_data$Title == "Mr" & full_data$Pclass == "1", ]$Age <- mean_age_by_Title_and_Pclass$mean_age[7]
full_data[is.na(full_data$Age) & full_data$Title == "Mr" & full_data$Pclass == '2', ]$Age <- mean_age_by_Title_and_Pclass$mean_age[8]
full_data[is.na(full_data$Age) & full_data$Title == "Mr" & full_data$Pclass == "3", ]$Age <- mean_age_by_Title_and_Pclass$mean_age[9]
full_data[is.na(full_data$Age) & full_data$Title == "Mrs" & full_data$Pclass == "1", ]$Age <- mean_age_by_Title_and_Pclass$mean_age[10]
full_data[is.na(full_data$Age) & full_data$Title == "Mrs" & full_data$Pclass == "2", ]$Age <- mean_age_by_Title_and_Pclass$mean_age[11]
full_data[is.na(full_data$Age) & full_data$Title == "Mrs" & full_data$Pclass == "3", ]$Age <- mean_age_by_Title_and_Pclass$mean_age[12]
full_data[is.na(full_data$Age) & full_data$Title == "Officer" & full_data$Pclass == "1", ]$Age <- mean_age_by_Title_and_Pclass$mean_age[14]

# 完成年齡遺漏值填補後，對之前還沒有辨識到 `identity` 的乘客再做一次辨識
full_data$identity <- as.character(full_data$identity)
full_data$identity[full_data$Age >= 15 & full_data$Sex == "male"] <- "Man"
full_data$identity[full_data$Age >= 15 & full_data$Sex == "female"] <- "Woman"
full_data$identity[full_data$Age < 15 & full_data$Sex == "male"] <- "Boy"
full_data$identity[full_data$Age < 15 & full_data$Sex == "female"] <- "Girl"
full_data$identity <- factor(full_data$identity)

# 完成年齡遺漏值填補後，對之前還沒有辨識到 `Child` 的乘客再做一次辨識
full_data$Child <- as.character(full_data$Child)
full_data$Child[full_data$Age < 15] <- "Child"
full_data$Child[full_data$Age >= 15] <- "Adult"
full_data$Child <- factor(full_data$Child)
```

檢查 titanic 資料集是否還有遺漏值的存在。

```{r}
# 計算遺漏值數量
sum(is.na(full_data %>% select(-Survived)))
# 填補遺漏值後的 summary
summary(full_data)
```

titanic 資料集中的 **Age**、**Fare**、**Embarked** 都沒有遺漏值的存在了，可以進行後續的建模啦！

# 訓練模型 (Training a Model)
使用機器學習的**隨機森林 (randomForest)** 演算法在訓練資料上建構我們的模型。

## 變數選擇 (Variable Selection)
回顧一下「特徵工程 (Feature Engineering)」小節，我們利用 titanic 資料集原始存在的變數衍生出很多新的變數，也發現那些衍生出來的變數都對 **Survived** 有一定的影響力，而在選擇模型的預測變數時，有重疊的變數我們將擇一選擇。變數選擇結果如下表：

原始變數 | 衍生變數 | 變數選擇
--- | --- | ---
Pclass | | Pclass
Name | Title | Title
Sex | | Sex
Age | Child | Child
Sex & Age | identity | 
SibSp & Parch| family_size、family_type | family_type
Ticket | group_size | group_size
Fare | | Fare
Embarked | | Embarked

**PassengerId** 變數基本上每個乘客都不一樣，**Cabin** 變數的遺漏值缺失很嚴重，所以在訓練模型時不考慮這兩個變數。

## 建立分類模型 (Building a Classification Model)
```{r message=FALSE}
full_data$Survived <- factor(full_data$Survived, levels = c("1", "0"))

# 將 train 資料提取出來作為訓練模型的資料
modeling_data <- full_data[full_data$Set == "Train", ]

# 找出決策樹進行分裂時所選擇的特徵個數之最佳值 (mtry)
library(randomForest)
model_err_rate = 1
for(i in 1:8)  # 8 為 Pclass, Sex, Child, Fare, Embarked, Title, family_type, group_size
{
  set.seed(754)
  result = randomForest(Survived ~ Pclass + Sex + Child + Fare + Embarked + Title + family_type + group_size, data = modeling_data, mtry = i, ntree = 500)
  model_err_rate[i] = mean(result$err.rate)
}
mtry_value = which.min(model_err_rate)

# 建立 randomForest 分類器
set.seed(754)
rfModel <- randomForest(Survived ~ Pclass + Sex + Child + Fare + Embarked + Title + family_type + group_size, data = modeling_data, mtry = mtry_value, ntree = 500)
```

## 變數的重要性 (Variable Importance)
```{r fig.align='center'}
# plot variable importance
varImpPlot(rfModel, main = "Importance of Variables")
# output variable importance
round(importance(rfModel), 2)

```

上面結果顯示了各個變數的節點純度，也就是說變數在分資料群時是否有判斷性，值愈高表示該變數對於模型的判別影響力愈大，可以作為往後利用其他演算法進行建模時刪減變數的依據。結果令我很訝異...從乘客姓名衍生出來的 **Title** 變數竟然最為重要！

# 衡量模型表現 (Evaluating Model Performance)

## 模型錯誤率 (Model Error)
```{r}
rfModel
```

對 OOB 樣本進行預測，錯誤率為 16.05%。
註：out-of-bag (OOB) 為每次抽樣中的袋外樣本

從混淆矩陣 (Confusion Matrix) 可看出：

* 模型將原本為 1 (存活) 的正確預測為 1 (存活) 的有 246 筆
* 模型將原本為 1 (存活) 的錯誤預測為 0 (死亡) 的有 96 筆
* 1 (存活) 的誤判率有 28.07%
* 模型將原本為 0 (死亡) 的正確預測為 0 (死亡) 的有 502 筆
* 模型將原本為 0 (死亡) 的錯誤預測為 1 (存活) 的有 47 筆
* 0 (死亡) 的誤判率有 8.56%


```{r fig.align='center'}
plot(rfModel, col = c("#000000", "#005ce6", "#ff0000"), lwd = 1.5,
     ylim=c(0,0.4), main = "Error Rate of rfModel")
legend("topright", legend = colnames(rfModel$err.rate),
       col = c("#000000", "#005ce6", "#ff0000"), fill = c("#000000", "#005ce6", "#ff0000"))
```

上圖顯示了 randomForest 模型的錯誤率，黑線顯示總體錯誤率低於 20%。藍線和紅線分別顯示 "存活" 和 "死亡" 的錯誤率，可以看到死亡的預測效果比預測存活還要好，而且預測存活的錯誤率比總體錯誤率還要高，為什麼會這樣呢？這是一個值得思考的問題！

## 模型準確度 (Model Accuracy)
```{r}
# 計算 accuracy
prediction <- predict(rfModel)
confusion_matrix <- table(modeling_data$Survived, prediction)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
accuracy
```

## ROC 曲線 (ROC Curve)
```{r message=FALSE, fig.align='center'}
# ROC Curve
library(ROCR)
probabilities <- predict(rfModel, type = "prob")[,1]
pred <- prediction(probabilities, labels = modeling_data$Survived)
perf <- performance(pred, "tpr", "fpr")
plot(perf)

# 計算 AUC (計算 ROC 曲線底下的面積)
perf <- performance(pred, "auc")
perf@y.values[[1]]
```

# Making our prediction
是時候來預測了！現在將使用上面所建立好的 RandomForest 模型應用在 titanic 中的測試資料 **test.csv** 來預測 **Survived**。

```{r}
# 將 test 資料提取出來做預測
predict_data <- full_data[full_data$Set == "Test", ]

# 對 test 資料做預測
predicted <- predict(rfModel, newdata = predict_data)

# 依照競賽的 Submission File Format，產出 2 個欄位的檔案：PassengerId、Survived (predicted)
solution <- data.frame(PassengerId = predict_data[, "PassengerId"], Survived = predicted)

# 看一下 solution 的前 10 筆資料
head(solution, n = 10)

# 將 solution 匯出為 csv 檔案
write.csv(solution, file = "result/r_randomForest_submission.csv", row.names = FALSE, quote = FALSE)
```

